import numpy as np
import tensorflow as tf
import msgnet


def set2set(nodes_in, segments, num_passes=2):
    """set2set [https://arxiv.org/abs/1511.06391]
    Based on implementation from DeepChem (PandeLab)

    :param nodes_in: (num_nodes, n_node_features) tensor
    :param segments: (num_nodes, ) tensor, places each node into (batch_idx,), (generated by set_len_to_segments function)
    :returns: (batch_size, output_size) tensor
    """
    batch_size = segments[-1] + 1
    num_features = nodes_in.get_shape()[1].value
    assert num_features is not None
    bias_init = np.concatenate(
        (
            np.zeros(num_features, dtype=np.float32),
            np.ones(num_features, dtype=np.float32),
            np.zeros(num_features, dtype=np.float32),
            np.zeros(num_features, dtype=np.float32),
        )
    )
    lstm_b = tf.get_variable("b_lstm", initializer=bias_init)
    lstm_U = tf.get_variable(
        "U_lstm",
        (2 * num_features, 4 * num_features),
        initializer=tf.contrib.layers.xavier_initializer(False),
    )

    def lstm_step(h, c):
        z = tf.nn.xw_plus_b(h, lstm_U, lstm_b)
        i = tf.nn.sigmoid(z[:, :num_features])
        f = tf.nn.sigmoid(z[:, num_features : 2 * num_features])
        o = tf.nn.sigmoid(z[:, 2 * num_features : 3 * num_features])
        z3 = z[:, 3 * num_features :]
        c_out = f * c + i * tf.nn.tanh(z3)
        h_out = o * tf.nn.tanh(c_out)

        return h_out, c_out

    q = tf.zeros((batch_size, num_features))
    lstm_c = tf.zeros((batch_size, num_features))

    mi = nodes_in
    for i in range(num_passes):
        e_node = tf.reduce_sum(mi * tf.gather(q, segments), -1)  # (total_nodes, )
        # Subtract maximum for numerical stability in softmax
        e_max = tf.segment_max(
            e_node, segments
        )  # (bs, ) # Does not work on GPU in TF 1.4
        e_max_e = tf.gather(e_max, segments)  # (total_nodes, )
        e_node -= e_max_e
        # softmax
        # Use unsorted_segment_sum because segment_sum does not work on GPU in TF 1.4
        a_node = tf.exp(e_node) / tf.gather(
            tf.unsorted_segment_sum(tf.exp(e_node), segments, segments[-1] + 1),
            segments,
        )  # (total_nodes,)
        a_node = tf.expand_dims(a_node, -1)  # (total_nodes, 1)
        # Use unsorted_segment_sum because segment_sum does not work on GPU in TF 1.4
        r = tf.unsorted_segment_sum(
            mi * a_node, segments, segments[-1] + 1
        )  # (bs, num_features)
        q_star = tf.concat((q, r), axis=1)
        q, lstm_c = lstm_step(q_star, lstm_c)

    num_features = q_star.get_shape()[1].value
    return q_star


class EdgeOutputFunction:
    def __init__(self, output_size=1):
        self.output_size = output_size

    def __call__(self, edges):
        edge_out = tf.identity(
            msgnet.defaults.mlp(
                edges,
                [edges.get_shape()[1].value, self.output_size],
                activation=msgnet.defaults.nonlinearity,
            ),
            "edge_out",
        )
        return edge_out


class ReadoutFunction:
    """ReadoutFunction
    Base class readout function """

    is_sum = True

    def __init__(self, output_size=1):
        self.output_size = output_size

    def __call__(self, nodes, segments):
        raise NotImplementedError()


class ReadoutAvgscalar(ReadoutFunction):
    is_sum = False

    def __call__(self, nodes, segments):
        nodes_size = int(nodes.get_shape()[1])
        pre_sum_fn = lambda x: msgnet.defaults.mlp(
            x,
            [nodes_size // 2, self.output_size],
            activation=msgnet.defaults.nonlinearity,
            weights_initializer=msgnet.defaults.initializer,
        )
        pre_sum = tf.identity(pre_sum_fn(nodes), name="node_contribution")
        tf.add_to_collection("node_contribution", pre_sum)
        graph_out = tf.segment_mean(pre_sum, segments)
        return graph_out


class ReadoutSumscalar(ReadoutFunction):
    is_sum = True

    def __call__(self, nodes, segments):
        nodes_size = int(nodes.get_shape()[1])
        pre_sum_fn = lambda x: msgnet.defaults.mlp(
            x,
            [nodes_size // 2, self.output_size],
            activation=msgnet.defaults.nonlinearity,
            weights_initializer=msgnet.defaults.initializer,
        )
        pre_sum = tf.identity(pre_sum_fn(nodes), name="node_contribution")
        tf.add_to_collection("node_contribution", pre_sum)
        graph_out = tf.segment_sum(pre_sum, segments)
        return graph_out


class ReadoutSumvector(ReadoutFunction):
    is_sum = True

    def __call__(self, nodes, segments):
        nodes_size = int(nodes.get_shape()[1])
        pre_sum_fn = lambda x: msgnet.defaults.mlp(
            x,
            [nodes_size, nodes_size // 2],
            activation=msgnet.defaults.nonlinearity,
            weights_initializer=msgnet.defaults.initializer,
        )
        post_sum_fn = lambda x: msgnet.defaults.mlp(
            x,
            [nodes_size // 2, self.output_size],
            activation=msgnet.defaults.nonlinearity,
            weights_initializer=msgnet.defaults.initializer,
        )
        pre_sum = tf.identity(pre_sum_fn(nodes), name="node_contribution")
        tf.add_to_collection("node_contribution", pre_sum)
        post_sum = tf.segment_sum(pre_sum, segments)
        graph_out = post_sum_fn(post_sum)
        return graph_out


class ReadoutAvgvector(ReadoutFunction):
    is_sum = True

    def __call__(self, nodes, segments):
        nodes_size = int(nodes.get_shape()[1])
        pre_sum_fn = lambda x: msgnet.defaults.mlp(
            x,
            [nodes_size, nodes_size // 2],
            activation=msgnet.defaults.nonlinearity,
            weights_initializer=msgnet.defaults.initializer,
        )
        post_sum_fn = lambda x: msgnet.defaults.mlp(
            x,
            [nodes_size // 2, self.output_size],
            activation=msgnet.defaults.nonlinearity,
            weights_initializer=msgnet.defaults.initializer,
        )
        pre_sum = tf.identity(pre_sum_fn(nodes), name="node_contribution")
        tf.add_to_collection("node_contribution", pre_sum)
        post_sum = tf.segment_mean(pre_sum, segments)
        graph_out = post_sum_fn(post_sum)
        return graph_out


class ReadoutSet2set(ReadoutFunction):
    is_sum = False

    def __call__(self, nodes, segments):
        nodes_size = int(nodes.get_shape()[1])
        graph_out = set2set(nodes, segments, num_passes=2)
        graph_out = msgnet.defaults.mlp(graph_out, [nodes_size // 2, self.output_size])
        return graph_out
